
{
  "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b5b37d-b38b-44ac-9715-fee512732f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create binary target: 1 if quality >= 6, else 0\n",
    "df['quality_label'] = (df['quality'] >= 6).astype(int)\n",
    "\n",
    "# Separate features and target\n",
    "X = df.drop(['quality', 'quality_label'], axis=1)\n",
    "y = df['quality_label']\n",
    "\n",
    "# Train-test split (80/20, stratified)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894f9c56-54dd-4a88-94bc-5f3b9808bce9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Configurations\n",
    "configs = [\n",
    "    {\"C\": 1.0, \"solver\": \"liblinear\"},\n",
    "    {\"C\": 0.1, \"solver\": \"liblinear\"},\n",
    "    {\"C\": 10.0, \"solver\": \"lbfgs\"}\n",
    "]\n",
    "\n",
    "# Training and evaluation\n",
    "for i, config in enumerate(configs, start=1):\n",
    "    print(f\"\\nðŸ”¹ Logistic Regression Config {i}: {config}\")\n",
    "    model = LogisticRegression(**config, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# Configurations
rf_configs = [
    {"n_estimators": 100, "max_depth": None, "random_state": 42},
    {"n_estimators": 200, "max_depth": 10, "random_state": 42},
    {"n_estimators": 50, "max_depth": 5, "random_state": 42}
]

# Training and evaluation
for i, config in enumerate(rf_configs, start=1):
    print(f"\nðŸŒ² Random Forest Config {i}: {config}")
    rf_model = RandomForestClassifier(**config)
    rf_model.fit(X_train, y_train)
    y_pred = rf_model.predict(X_test)
    print(classification_report(y_test, y_pred)
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report

# Configurations
mlp_configs = [
    {"hidden_layer_sizes": (50,), "max_iter": 300, "random_state": 42},
    {"hidden_layer_sizes": (100, 50), "max_iter": 500, "random_state": 42},
    {"hidden_layer_sizes": (200,), "activation": "tanh", "max_iter": 500, "random_state": 42}
]

# Training and evaluation
for i, config in enumerate(mlp_configs, start=1):
    print(f"\n MLPClassifier Config {i}: {config}")
    mlp_model = MLPClassifier(**config)
    mlp_model.fit(X_train, y_train)
    y_pred = mlp_model.predict(X_test)
    print(classification_report(y_test, y_pred))